# -*- coding: utf-8 -*-
"""Homework2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14FutBXgN9wyeLHUszj__cejO7r1-jxIy

# **HOMEWORK - 2**
"""

import numpy
import urllib
import scipy.optimize
import random
from sklearn import linear_model
import gzip
from collections import defaultdict
from sklearn.metrics import accuracy_score, mean_squared_error

import warnings
warnings.filterwarnings("ignore")

def assertFloat(x):
    assert type(float(x)) == float

def assertFloatList(items, N):
    assert len(items) == N
    assert [type(float(x)) for x in items] == [float]*N

"""# **Model Pipelines and Diagnostics**"""

f = open("5year.arff", 'r')

# Read and parse the data
while not '@data' in f.readline():
    pass

dataset = []
for l in f:
    if '?' in l: # Missing entry
        continue
    l = l.split(',')
    values = [1] + [float(x) for x in l]
    values[-1] = values[-1] > 0 # Convert to bool
    dataset.append(values)

X = [d[:-1] for d in dataset]
y = [d[-1] for d in dataset]

answers = {}

"""# Question 1"""

def accuracy(predictions, y):
  return accuracy_score(y, predictions)

def BER(predictions, y):
  TP = sum([(pred and label) for (pred,label) in zip(predictions, y)])
  FP = sum([(pred and not label) for (pred,label) in zip(predictions, y)])
  TN = sum([(not pred and not label) for (pred,label) in zip(predictions, y)])
  FN = sum([(not pred and label) for (pred,label) in zip(predictions, y)])
  FPR = FP / (FP + TN)
  FNR = FN / (TP + FN)
  # acc = (TP + TN)/ (TP + TN + FP + FN)
  # print(acc)
  return 1/2 * (FPR + FNR)

mod = linear_model.LogisticRegression(C=1)
mod.fit(X,y)

pred = mod.predict(X)

acc1 = accuracy(pred, y)
ber1 = BER(pred, y)
answers['Q1'] = [acc1, ber1] # Accuracy and balanced error rate

assertFloatList(answers['Q1'], 2)

answers['Q1']

"""### QUESTION 2"""

mod2 = linear_model.LogisticRegression(C=1, class_weight='balanced')
mod2.fit(X,y)

pred2 = mod2.predict(X)

acc2 = accuracy(pred2, y)
ber2 = BER(pred2, y)
answers['Q2'] = [acc2, ber2] # Accuracy and balanced error rate

answers['Q2']

assertFloatList(answers['Q2'], 2)

"""### QUESTION 3"""

random.seed(3)
random.shuffle(dataset)

X = [d[:-1] for d in dataset]
y = [d[-1] for d in dataset]

Xtrain, Xvalid, Xtest = X[:len(X)//2], X[len(X)//2:(3*len(X))//4], X[(3*len(X))//4:]
ytrain, yvalid, ytest = y[:len(X)//2], y[len(X)//2:(3*len(X))//4], y[(3*len(X))//4:]

len(Xtrain), len(Xvalid), len(Xtest)

mod3 = linear_model.LogisticRegression(class_weight='balanced')
mod3.fit(Xtrain,ytrain)

pred3_train = mod3.predict(Xtrain)
pred3_test = mod3.predict(Xtest)
pred3_valid = mod3.predict(Xvalid)

ber3_train = BER(pred3_train, ytrain)
ber3_test = BER(pred3_test, ytest)
ber3_valid = BER(pred3_valid, yvalid)

answers['Q3'] = [ber3_train, ber3_valid, ber3_test]

answers['Q3']

assertFloatList(answers['Q3'], 3)

"""### QUESTION 4"""

answers['Q4']=[]
def reg_pipeline(reg):
    mod4 = linear_model.LogisticRegression(C=reg, class_weight='balanced')
    mod4.fit(Xtrain,ytrain)
    pred4_valid = mod4.predict(Xvalid)
    answers['Q4'].append(BER(pred4_valid, yvalid))

start = 0.0001
for i in range(9):
  # print(start)
  reg_pipeline(start)
  start *=10

answers['Q4']

assertFloatList(answers['Q4'], 9)

"""### QUESTION 5"""

bestC = 100.0
mod5 = linear_model.LogisticRegression(C=bestC, class_weight='balanced')
mod5.fit(Xtrain,ytrain)
pred5_test = mod5.predict(Xtest)
ber5 = BER(pred5_test, ytest)
answers['Q5'] = [bestC, ber5]

answers['Q5']

assertFloatList(answers['Q5'], 2)

"""## **RECOMMENDATION TASKS**"""

f = open("young_adult_10000.json")
dataset = []
for l in f:
    dataset.append(eval(l))
dataset[0]

dataTrain = dataset[:9000]
dataTest = dataset[9000:]

"""### QUESTION 6"""

# Some data structures you might want

usersPerItem = defaultdict(set) # Maps an item to the users who rated it
itemsPerUser = defaultdict(set) # Maps a user to the items that they rated
reviewsPerUser = defaultdict(list)
reviewsPerItem = defaultdict(list)
ratingDict = {} # To retrieve a rating for a specific user/item pair

for d in dataTrain:
  item = d['book_id']
  user = d['user_id']
  usersPerItem[item].add(user)
  itemsPerUser[user].add(item)
  reviewsPerUser[user].append(d)
  reviewsPerItem[item].append(d)
  # ratingDict[(user, item)] = reviews
# global_avg = rating/len(dataTrain)
global_avg =  sum([d['rating'] for d in dataTrain])/len(dataTrain)
global_avg

def Jaccard(s1, s2):
    numer = len(s1.intersection(s2))
    denom = len(s1.union(s2))
    return numer / denom

def mostSimilar(i, N):
  sim_item = []
  users = usersPerItem[i]
  for i2 in usersPerItem:
    if i==i2:
      continue
    sim_item.append((Jaccard(users, usersPerItem[i2]), i2))
  sim_item.sort(reverse=True)
  return sim_item[:N]

answers['Q6']= mostSimilar('2767052', 10)

answers['Q6']

assert len(answers['Q6']) == 10
assertFloatList([x[0] for x in answers['Q6']], 10)

"""### QUESTION 7"""

def get_mean_item(item):
  if(len(reviewsPerItem[item])==0):
    return global_avg
  mean = sum([int(d['rating']) for d in reviewsPerItem[item]])/len(reviewsPerItem[item])
  return mean

def predict_rating_item(user, item):
  if user not in itemsPerUser or item not in usersPerItem:
    return global_avg
  mean_1 = get_mean_item(item)
  total_sim = 0
  weighted_sum = 0
  for d in reviewsPerUser[user]:
    i = d['book_id']
    rating = d['rating']
    if i == item: continue
    mean_2 = get_mean_item(i)
    sim = Jaccard(usersPerItem[item], usersPerItem[i])
    total_sim += sim
    weighted_sum += (rating-mean_2)*sim
  if(total_sim == 0):
    return mean_1
  return mean_1 + weighted_sum/total_sim

pred7 = [predict_rating_item(d['user_id'], d['book_id']) for d in dataTest]

mse7 = mean_squared_error([d['rating']for d in dataTest], pred7)
answers['Q7'] = mse7

answers['Q7']

assertFloat(answers['Q7'])

"""### QUESTION 8"""

def get_mean_user(user):
  if(len(reviewsPerUser[user])==0):
    return global_avg
  mean = sum([int(d['rating']) for d in reviewsPerUser[user]])/len(reviewsPerUser[user])
  return mean

def predict_rating_user(user, item):
  if user not in itemsPerUser or item not in usersPerItem:
    return global_avg
  mean_1 = get_mean_user(user)
  total_sim = 0
  weighted_sum = 0
  for d in reviewsPerItem[item]:
    u = d['user_id']
    rating = d['rating']
    if u == user: continue
    mean_2 = get_mean_user(u)
    sim = Jaccard(itemsPerUser[user], itemsPerUser[u])
    total_sim += sim
    weighted_sum += (rating-mean_2)*sim
  if(total_sim == 0):
    return mean_1
  return mean_1 + weighted_sum/total_sim

pred8 = [predict_rating_user(d['user_id'], d['book_id']) for d in dataTest]

mse8 = mean_squared_error([d['rating']for d in dataTest], pred8)
answers['Q8'] = mse8

answers['Q8']

assertFloat(answers['Q8'])

f = open("answers_hw2.txt", 'w')
f.write(str(answers) + '\n')
f.close()


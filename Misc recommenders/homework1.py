# -*- coding: utf-8 -*-
"""Homework 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oGwIj5MW8eZ1r_1uWXF4b-TBfeC0wf0n

### **HOMEWORK - 1**

Name - Devanshi Garg

PID - A69036540
"""

import json
from matplotlib import pyplot as plt
from collections import defaultdict
from sklearn import linear_model
from sklearn.metrics import precision_score, mean_squared_error
import numpy
import random
import gzip
import math
import sklearn
import pandas

import warnings
warnings.filterwarnings("ignore")

def assertFloat(x): # Checks that an answer is a float
    assert type(float(x)) == float

def assertFloatList(items, N):
    assert len(items) == N
    assert [type(float(x)) for x in items] == [float]*N

answers = {} # Dictionary for answers

"""### **REGRESSION TASK**"""

f = open("young_adult_10000.json")
dataset = []
for l in f:
  dataset.append(json.loads(l))

dataset[0]

"""# QUESTION 1"""

def feature1(datum):
  count = datum['review_text'].count('!')
  return [1] + [count]

X1 = [feature1(d) for d in dataset]

y1 = [d['rating'] for d in dataset]
len(y1)

theta1,residuals1,rank1,s1 = numpy.linalg.lstsq(X1, y1)

def mean_squar_error(X,y,theta): # NOT USING but just added to verify the answer
  pred = numpy.dot(X,theta)
  size = len(y)
  mse = sum([(y[i] - pred[i])**2 for i in range(size)])/size
  return mse

mse1 = mean_squared_error(y1, numpy.dot(X1,theta1))
mse1

answers['Q1'] = [theta1[0], theta1[1], mse1]

answers['Q1']

assertFloatList(answers['Q1'], 3) # Answer must be three floats

"""# QUESTION 2"""

def feature2(datum):
  count = datum['review_text'].count('!')
  length = len(datum['review_text'])
  return [1] + [length] + [count]

X2 = [feature2(d) for d in dataset]

y2 = [d['rating'] for d in dataset]

theta2,residuals2,rank2,s2 = numpy.linalg.lstsq(X2, y2)

theta2

mse2 = mean_squared_error(y2, numpy.dot(X2,theta2))
mse2

answers['Q2'] = [theta2[0], theta2[1], theta2[2], mse2]

assertFloatList(answers['Q2'], 4)

answers['Q2']

"""# QUESTION 3"""

def feature3(datum, degree):  # COMMON TO BOTH QUESTIONS 3 AND 4
  feat = [1]
  count = datum['review_text'].count('!')
  for deg in range(1, degree + 1):
    feat += [pow(count, deg)]
  return feat

y3 = [d['rating'] for d in dataset]

answers['Q3'] = []
for degree in range(1,6):
  X3 = [feature3(d, degree) for d in dataset]
  theta3,residuals3,rank3,s3 = numpy.linalg.lstsq(X3, y3)
  mse = mean_squared_error(y3, numpy.dot(X3,theta3))
  answers['Q3'].append(mse)

answers['Q3']

assertFloatList(answers['Q3'], 5) # List of length 5

"""# QUESTION 4"""

y4_train = y3[:len(y3)//2]
y4_test= y3[len(y3)//2:]

len(y4_test)

answers['Q4'] = []
for degree in range(1,6):
  X4_train = [feature3(d, degree) for d in dataset][:len(y3)//2]
  X4_test = [feature3(d, degree) for d in dataset][len(y3)//2:]
  theta4,residuals4,rank4,s4 = numpy.linalg.lstsq(X4_train, y4_train)
  mse = mean_squared_error(y4_test, numpy.dot(X4_test,theta4))
  answers['Q4'].append(mse)

answers['Q4']

"""# QUESTION 5"""

y = [d['rating'] for d in dataset]
y5_train = y[:len(y)//2]
y5_test = y[len(y)//2:]

len(y5_test)

"""In order to minimise the Mean Absolute Error (MAE) we need to find a theta such that sum of deviations from theta should be minimum. Hence, theta must be equal to the median of the set."""

theta5 = numpy.median(y5_train)

theta5

def mean_abs_error(y, theta):
  mae = sum([abs(y[i]- theta) for i in range(len(y))])/len(y)
  return mae

answers['Q5'] = mean_abs_error(y5_test, theta5)

assertFloat(answers['Q5'])

answers['Q5']

"""### **CLASSIFICATION TASK**"""

f = open("beer_50000.json")
dataset = []
for l in f:
    if 'user/gender' in l:
        dataset.append(eval(l))

len(dataset)

dataset[0]

"""# QUESTION 6"""

def feature6(datum):
  count = datum['review/text'].count('!')
  return [1] + [count]

X6 = [feature6(d) for d in dataset]

y6 = [d['user/gender'] == 'Female' for d in dataset]

mod = sklearn.linear_model.LogisticRegression()
mod.fit(X6,y6)

predictions = mod.predict(X6)

TP = sum([(pred and label) for (pred,label) in zip(predictions, y6)])
FP = sum([(pred and not label) for (pred,label) in zip(predictions, y6)])
TN = sum([(not pred and not label) for (pred,label) in zip(predictions, y6)])
FN = sum([(not pred and label) for (pred,label) in zip(predictions, y6)])

FNR = FN / (TP + FN) # to calculate BER

FPR = FP / (FP + TN)

BER = 1/2 * (FPR + FNR)

answers['Q6'] = [TP, TN, FP, FN, BER]

answers['Q6']

"""# QUESTION 7"""

mod2 = sklearn.linear_model.LogisticRegression(class_weight='balanced') # UPDATED THE MODEL
mod2.fit(X6,y6) # used the same test and training set

predictions = mod2.predict(X6)
TP = sum([(pred and label) for (pred,label) in zip(predictions, y6)])
FP = sum([(pred and not label) for (pred,label) in zip(predictions, y6)])
TN = sum([(not pred and not label) for (pred,label) in zip(predictions, y6)])
FN = sum([(not pred and label) for (pred,label) in zip(predictions, y6)])
FNR = FN / (TP + FN)
FPR = FP / (FP + TN)
BER = 1/2 * (FPR + FNR)
answers['Q7'] = [TP, TN, FP, FN, BER]
answers['Q7']

"""#  QUESTION 8"""

y_probabilities = mod2.predict_proba(X6)[:, 1]

df = pandas.DataFrame({'true_label': y6, 'prediction': predictions, 'probability': y_probabilities}) # dataframe created to store labels, predictions and probabilities

df.head()

df.sort_values(by='probability',ascending=False,inplace=True)

df.head()

K = [1, 10, 100, 1000, 10000]
answers['Q8'] = []
for k in K:
    dfK = df.head(k)
    print(dfK['true_label'])
    precision =  sum([dfK['true_label']])/k
    # precision  = numpy.mean(dfK['true_label'])
    # precision = precision_score(dfK[0], dfK[1])
    answers['Q8'].append(precision)

answers['Q8']

f = open("answers_hw1.txt", 'w') # Write answers to a file
f.write(str(answers) + '\n')
f.close()